# kanji-2-kana

æ—¥æœ¬èªã®æ¼¢å­—æ··ã˜ã‚Šæ–‡ç« ã‚’ã‚«ã‚¿ã‚«ãƒŠã«å¤‰æ›ã™ã‚‹ãŸã‚ã®å­¦ç¿’ãƒ»æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã™ã€‚
Gemma-3 1Bãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€SFTãŠã‚ˆã³GRPOï¼ˆæ”¹è‰¯ç‰ˆï¼‰ã§å­¦ç¿’ã—ã€é«˜é€Ÿãƒ»é«˜ç²¾åº¦ãªæ¨è«–ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æä¾›ã—ã¾ã™ã€‚

---

## ğŸ“‹ å¿…è¦ç’°å¢ƒ

- Python 3.10ä»¥ä¸Š
- CUDAå¯¾å¿œGPU (æ¨å¥¨: 8GBä»¥ä¸Š)
- Git

### ä¾å­˜ç®¡ç† (uv)

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ `uv` ã‚’ç”¨ã„ã¦ä¾å­˜ã‚’ç®¡ç†ã—ã¾ã™ã€‚`uv.lock` ã«ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚

```bash
# ä¾å­˜ã‚’ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync
```

æ–°ã—ã„ä¾å­˜ã‚’è¿½åŠ ãƒ»æ›´æ–°ã™ã‚‹ã«ã¯ï¼š
```bash
uv add <ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å>
```

ä½¿ã„çµ‚ã‚ã£ãŸã‚‰:
```bash
uv remove <ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸å>
```

---

## ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
./
â”œâ”€â”€ data/                      # å…ƒãƒ‡ãƒ¼ã‚¿ (JSONLå½¢å¼)
â”œâ”€â”€ train/                     # å­¦ç¿’ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ train_gemma3_1b_kanji2kana_sft.py          # SFTå­¦ç¿’
â”‚   â””â”€â”€ train_gemma3_1b_kanji2kana_grpo_improved.py # æ”¹è‰¯ç‰ˆGRPOå­¦ç¿’
â”œâ”€â”€ inference/                 # æ¨è«–ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ inference_gemma3_kanji2kana.py  # é€šå¸¸æ¨è«–
â”‚   â””â”€â”€ fast_inference.py              # è¶…é«˜é€Ÿæ¨è«–ï¼ˆãƒãƒƒãƒã€pipelineã€vLLMå¯¾å¿œï¼‰
â”œâ”€â”€ model/                     # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜å…ˆ
â”‚   â”œâ”€â”€ gemma3_1b_kanji2kana_sft/
â”‚   â””â”€â”€ gemma3_1b_kanji2kana_sft_merged/
â””â”€â”€ README.md                  # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

---

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿æº–å‚™

å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã¯ `data/` ä»¥ä¸‹ã®JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚å„è¡Œã«ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å«ã‚€å½¢å¼ã§ã™ï¼š

```json
{
  "output": "æ¼¢å­—æ··ã˜ã‚Šæ–‡ç« ",
  "input": "æ­£è§£ã‚«ã‚¿ã‚«ãƒŠæ–‡ç« "
}
```

ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã‹ã‘ãªãŒã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

- **SFT**: `train/train_gemma3_1b_kanji2kana_sft.py` å†…ã® `load_streaming_dataset` é–¢æ•°
- **GRPO**: `train/train_gemma3_1b_kanji2kana_grpo_improved.py` å†…ã® `load_grpo_dataset` é–¢æ•°

ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡ã‚„æœ€å¤§ã‚µãƒ³ãƒ—ãƒ«æ•°ã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§è¨­å®šå¯èƒ½ã§ã™ã€‚

---

## ğŸš€ å­¦ç¿’

### 1. SFT (æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°)

```bash
uv run python train/train_gemma3_1b_kanji2kana_sft.py
```

ä¸»ãªè¨­å®šï¼š
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 64
- å‹¾é…è“„ç©: 2
- LoRAãƒ©ãƒ³ã‚¯: 32
- å­¦ç¿’ç‡: 8e-4

### 2. æ”¹è‰¯ç‰ˆ GRPO (å¼·åŒ–å­¦ç¿’)

```bash
uv run python train/train_gemma3_1b_kanji2kana_grpo_improved.py
```

æ”¹è‰¯ç‰ˆå ±é…¬é–¢æ•°:
1. ã‚«ã‚¿ã‚«ãƒŠç´”åº¦ (å¥èª­ç‚¹ãƒ»è¨˜å·ã‚’é™¤å¤–)
2. ä¸é©åˆ‡æ–‡å­—ãƒšãƒŠãƒ«ãƒ†ã‚£ (ã²ã‚‰ãŒãªãƒ»æ¼¢å­—)
3. é•·ã•é©åˆ‡æ€§
4. å¥èª­ç‚¹ä¿æŒ
5. å®Œå…¨æ€§
6. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆéµå®ˆ
7. æ–‡å­—ç¨®ä¸€è²«æ€§
8. ç‰¹æ®Šæ–‡å­—å‡¦ç†

è¨­å®šä¾‹:
- ãƒãƒƒãƒã‚µã‚¤ã‚º: 16
- å‹¾é…è“„ç©: 4
- LoRAãƒ©ãƒ³ã‚¯: 64
- å­¦ç¿’ç‡: 5e-5

---

## ğŸ¤– æ¨è«–

### 1. é€šå¸¸æ¨è«–

```bash
uv run python inference/inference_gemma3_kanji2kana.py
```

- **å¯¾è©±ãƒ¢ãƒ¼ãƒ‰**: å…¥åŠ›ã‚’é€æ¬¡å¤‰æ›
- **ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰**: è¤‡æ•°è¡Œã‚’ä¸€æ‹¬å¤‰æ›
- **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¢ãƒ¼ãƒ‰**: `inference.py input.txt output.txt`

### 2. è¶…é«˜é€Ÿæ¨è«–

```bash
uv run python inference/fast_inference.py
```

- PyTorch 2.0 `torch.compile` ã§ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
- `max_new_tokens=50`, `temperature=0.0`, `do_sample=False`
- ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’256ã«çŸ­ç¸®
- 4bité‡å­åŒ– + ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–
- å¯¾è©± / ãƒãƒƒãƒ / ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰

### 3. Transformers Pipeline ãƒ¢ãƒ¼ãƒ‰

```bash
uv run python inference/fast_inference.py --hf
```

- 8bité‡å­åŒ–ï¼‹device_map="auto"
- `text-generation` pipeline ã§ç°¡æ˜“æ¨è«–

### 4. vLLM ãƒ¢ãƒ¼ãƒ‰

```bash
uv run python inference/fast_inference.py --vllm
```

- vLLM API ã§ãƒãƒƒãƒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
- `LLM.generate` ã«ã‚ˆã‚‹é«˜é€Ÿæ¨è«–

### 5. é€Ÿåº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

```bash
uv run python inference/fast_inference.py --benchmark
```

ãƒãƒƒãƒï¼é€æ¬¡ãã‚Œãã‚Œã®å¹³å‡æ¨è«–æ™‚é–“ã¨æ–‡å­—/ç§’ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

---

## ğŸ“ ä½¿ç”¨ä¾‹

```bash
# SFTå­¦ç¿’
uv run python train/train_gemma3_1b_kanji2kana_sft.py

# é€šå¸¸æ¨è«–
uv run python inference/inference_gemma3_kanji2kana.py

# è¶…é«˜é€Ÿæ¨è«–
uv run python inference/fast_inference.py

# HF pipelineæ¨è«–
uv run python inference/fast_inference.py --hf

# vLLMæ¨è«–
uv run python inference/fast_inference.py --vllm

# é€Ÿåº¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
uv run python inference/fast_inference.py --benchmark
```

---

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License
